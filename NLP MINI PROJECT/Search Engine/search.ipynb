{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dd7ddb",
   "metadata": {},
   "source": [
    "# MIT Art, Design and Technology University  \n",
    "### MIT School of Computing, Pune  \n",
    "### Department of Information Technology  \n",
    "\n",
    "---\n",
    "\n",
    "## Participative Learning Activity  \n",
    "### Subject – Natural Language Processing  \n",
    "### Topic – Information Retrieval and Extraction: Building a Simple Search Engine  \n",
    "### Academic Year 2025 – 2026 (SEM I)  \n",
    "### Course Coordinator – Prof. Kalyani Lokhande  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e04ae3",
   "metadata": {},
   "source": [
    "###  Phase 1 – Creating the Document Dataset\n",
    "\n",
    "Before building a search engine, we need a **collection of text documents** that the engine can search through.  \n",
    "In real life, these could be:\n",
    "- webpages,  \n",
    "- articles,  \n",
    "- research papers, or  \n",
    "- news stories.\n",
    "\n",
    "For our project, we’ll create a **small custom dataset** — just a few short text paragraphs on different topics.  \n",
    "\n",
    "This dataset will act as our **“mini knowledge base”** for the search engine.  \n",
    "Later, we’ll preprocess it, index it (convert to vectors), and search it.\n",
    "\n",
    "###  Objective of this phase:\n",
    "- Create and store a few sample text documents  \n",
    "- Save them in a DataFrame (and optionally in a CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ddc382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Natural Language Processing enables computers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Information retrieval is about searching and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Machine learning algorithms improve automatica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Neural networks are used for image recognition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Search engines use indexing and ranking techni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_ID                                               Text\n",
       "0            1  Natural Language Processing enables computers ...\n",
       "1            2  Information retrieval is about searching and r...\n",
       "2            3  Machine learning algorithms improve automatica...\n",
       "3            4  Neural networks are used for image recognition...\n",
       "4            5  Search engines use indexing and ranking techni..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a small document collection\n",
    "documents = [\n",
    "    \"Natural Language Processing enables computers to understand human language.\",\n",
    "    \"Information retrieval is about searching and ranking relevant documents.\",\n",
    "    \"Machine learning algorithms improve automatically through experience.\",\n",
    "    \"Neural networks are used for image recognition and NLP tasks.\",\n",
    "    \"Search engines use indexing and ranking techniques to find information quickly.\"\n",
    "]\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame({\"Document_ID\": range(1, len(documents)+1), \"Text\": documents})\n",
    "\n",
    "# Display dataset\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a15c27",
   "metadata": {},
   "source": [
    "###  Phase 2 – Text Preprocessing\n",
    "\n",
    "Before we can build a search engine, we must clean and normalize the text.  \n",
    "Raw text often contains:\n",
    "- Punctuation marks  \n",
    "- Uppercase/lowercase inconsistencies  \n",
    "- Stopwords (like *the, is, and, of*), which add no real meaning\n",
    "\n",
    "In this phase, we’ll:\n",
    "1. Convert all text to lowercase  \n",
    "2. Remove punctuation  \n",
    "3. Tokenize (split text into words)  \n",
    "4. Remove stopwords  \n",
    "5. Lemmatize words (convert them to their base form, e.g., *computers → computer*)  \n",
    "\n",
    "This makes all documents **uniform and comparable**, allowing the system to index and match them effectively.\n",
    "\n",
    "###  Objective of this phase:\n",
    "To clean and prepare all text documents so they are ready for vectorization and search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3bdfb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34dc3932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\astam\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: click, nltk\n",
      "Successfully installed click-8.3.0 nltk-3.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ae324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\astam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\astam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\astam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Natural Language Processing enables computers ...</td>\n",
       "      <td>natural language processing enables computer u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Information retrieval is about searching and r...</td>\n",
       "      <td>information retrieval searching ranking releva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Machine learning algorithms improve automatica...</td>\n",
       "      <td>machine learning algorithm improve automatical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Neural networks are used for image recognition...</td>\n",
       "      <td>neural network used image recognition nlp task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Search engines use indexing and ranking techni...</td>\n",
       "      <td>search engine use indexing ranking technique f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_ID                                               Text  \\\n",
       "0            1  Natural Language Processing enables computers ...   \n",
       "1            2  Information retrieval is about searching and r...   \n",
       "2            3  Machine learning algorithms improve automatica...   \n",
       "3            4  Neural networks are used for image recognition...   \n",
       "4            5  Search engines use indexing and ranking techni...   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  natural language processing enables computer u...  \n",
       "1  information retrieval searching ranking releva...  \n",
       "2  machine learning algorithm improve automatical...  \n",
       "3     neural network used image recognition nlp task  \n",
       "4  search engine use indexing ranking technique f...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources (only first time)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    # 2. Remove punctuation and non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # 3. Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # 4. Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # 5. Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # 6. Rejoin into cleaned string\n",
    "    cleaned = ' '.join(tokens)\n",
    "    return cleaned\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"Cleaned_Text\"] = df[\"Text\"].apply(preprocess_text)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042726a9",
   "metadata": {},
   "source": [
    "### Phase 3 – TF-IDF Indexing\n",
    "\n",
    "After cleaning and preprocessing the text, the next step is to **convert text into numerical form** so that it can be compared mathematically.  \n",
    "Search engines use such numeric representations to measure how similar a user’s query is to each document.\n",
    "\n",
    "We will use **TF-IDF (Term Frequency – Inverse Document Frequency)**, which represents how important a word is to a document in the collection.\n",
    "\n",
    "- **Term Frequency (TF):** measures how often a word appears in a document.  \n",
    "- **Inverse Document Frequency (IDF):** reduces the weight of common words that appear in many documents.\n",
    "\n",
    "The resulting TF-IDF value gives higher importance to words that are **unique and meaningful** within each document.\n",
    "\n",
    "### Objective of this phase:\n",
    "1. Convert all preprocessed documents into TF-IDF vectors.  \n",
    "2. Prepare them for similarity measurement and ranking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff73d3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (sample): ['algorithm' 'automatically' 'computer' 'document' 'enables' 'engine'\n",
      " 'experience' 'find' 'human' 'image' 'improve' 'indexing' 'information'\n",
      " 'language' 'learning']\n",
      "\n",
      "TF-IDF Matrix Shape: (5, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Cleaned_Text\"])\n",
    "\n",
    "# Display feature names (vocabulary)\n",
    "print(\"Vocabulary (sample):\", vectorizer.get_feature_names_out()[:15])\n",
    "\n",
    "# Show the TF-IDF matrix shape\n",
    "print(\"\\nTF-IDF Matrix Shape:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460597b",
   "metadata": {},
   "source": [
    "\n",
    "### Phase 4 – Implementing the Search Function\n",
    "\n",
    "After converting documents into TF-IDF vectors, we can now build the core of our search engine.  \n",
    "The goal of this phase is to take a **user query**, compare it with all documents, and return the most relevant ones.\n",
    "\n",
    "To do this, we will use **Cosine Similarity** — a mathematical measure of similarity between two vectors.\n",
    "\n",
    "- **Cosine Similarity** = (A · B) / (||A|| × ||B||)  \n",
    "  It gives a value between 0 and 1, where 1 means identical and 0 means completely different.\n",
    "\n",
    "Steps:\n",
    "1. Take a user query and preprocess it the same way as documents.  \n",
    "2. Convert the query into a TF-IDF vector using the same vocabulary.  \n",
    "3. Compute cosine similarity between the query vector and all document vectors.  \n",
    "4. Sort documents by similarity score and display the top results.\n",
    "\n",
    "### Objective of this phase:\n",
    "To enable the system to accept a search query and return ranked documents based on their relevance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c922ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Similarity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Search engines use indexing and ranking techni...</td>\n",
       "      <td>0.481513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Information retrieval is about searching and r...</td>\n",
       "      <td>0.375242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Neural networks are used for image recognition...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_ID                                               Text  \\\n",
       "4            5  Search engines use indexing and ranking techni...   \n",
       "1            2  Information retrieval is about searching and r...   \n",
       "3            4  Neural networks are used for image recognition...   \n",
       "\n",
       "   Similarity_Score  \n",
       "4          0.481513  \n",
       "1          0.375242  \n",
       "3          0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def search_engine(query, df, vectorizer, tfidf_matrix, top_n=3):\n",
    "    # Preprocess the query\n",
    "    cleaned_query = preprocess_text(query)\n",
    "\n",
    "    # Transform the query using the same TF-IDF vectorizer\n",
    "    query_vec = vectorizer.transform([cleaned_query])\n",
    "\n",
    "    # Compute cosine similarity between query and all documents\n",
    "    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "\n",
    "    # Get top N most similar documents\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "\n",
    "    # Prepare results\n",
    "    results = df.iloc[top_indices][[\"Document_ID\", \"Text\"]].copy()\n",
    "    results[\"Similarity_Score\"] = similarities[top_indices]\n",
    "    return results\n",
    "\n",
    "# Example search\n",
    "query = \"ranking documents in search engines\"\n",
    "search_results = search_engine(query, df, vectorizer, tfidf_matrix)\n",
    "search_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf911225",
   "metadata": {},
   "source": [
    "### Phase 5 – Ranking and Result Interpretation\n",
    "\n",
    "Once the similarity scores are calculated, the search engine ranks the results in descending order of relevance.  \n",
    "This ranking helps the user quickly access the most useful documents.\n",
    "\n",
    "**How ranking works:**\n",
    "1. Each document receives a similarity score (0–1) that indicates how close it is to the user’s query.\n",
    "2. The documents are sorted by this score — the highest-scoring ones appear first.\n",
    "3. The top results are presented to the user as the most relevant answers.\n",
    "\n",
    "In this simplified implementation, ranking is based purely on **cosine similarity** using TF-IDF vectors.  \n",
    "More advanced search engines (like Google) also consider factors such as link authority, freshness, and user engagement.\n",
    "\n",
    "### Objective of this phase:\n",
    "- Display search results ranked by relevance.  \n",
    "- Interpret how similarity scores affect the ranking order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df2239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Results:\n",
      "\n",
      " Document_ID                                                                            Text  Similarity_Score\n",
      "           5 Search engines use indexing and ranking techniques to find information quickly.               0.0\n",
      "           4                   Neural networks are used for image recognition and NLP tasks.               0.0\n",
      "           3           Machine learning algorithms improve automatically through experience.               0.0\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "Top Results:\n",
      "\n",
      " Document_ID                                                                            Text  Similarity_Score\n",
      "           4                   Neural networks are used for image recognition and NLP tasks.          0.377964\n",
      "           5 Search engines use indexing and ranking techniques to find information quickly.          0.000000\n",
      "           3           Machine learning algorithms improve automatically through experience.          0.000000\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to interactively test queries\n",
    "while True:\n",
    "    query = input(\"Enter your search query (or type 'exit' to stop): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    results = search_engine(query, df, vectorizer, tfidf_matrix, top_n=3)\n",
    "    print(\"\\nTop Results:\\n\")\n",
    "    print(results.to_string(index=False))\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258f532",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
