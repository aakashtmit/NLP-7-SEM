{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f77d5f4",
   "metadata": {},
   "source": [
    "# MIT Art, Design and Technology University  \n",
    "### MIT School of Computing, Pune  \n",
    "### Department of Information Technology  \n",
    "\n",
    "---\n",
    "\n",
    "## Experiential Learning Activity  \n",
    "### Subject – Natural Language Processing  \n",
    "### Topic – Build Your Own Mini NLP Tool: Language Detection  \n",
    "### Academic Year 2025 – 2026 (SEM I)  \n",
    "### Course Coordinator – Prof. Kalyani Lokhande  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97afd48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: six in c:\\users\\astam\\appdata\\roaming\\python\\python311\\site-packages (from langdetect) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\astam\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\astam\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\astam\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "All libraries installed and imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install langdetect pandas matplotlib\n",
    "\n",
    "# Import required modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# Fix randomness for consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "print(\"All libraries installed and imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee77a9",
   "metadata": {},
   "source": [
    "### Phase 1 – Creating or Loading the Dataset\n",
    "\n",
    "To test the language detection tool, we need a collection of short sentences written in different languages.  \n",
    "Each sentence will represent a unique language such as English, Hindi, French, Spanish, and others.  \n",
    "\n",
    "We will first create a small in-memory dataset with sample multilingual text.  \n",
    "Later, the same approach can be applied to a larger dataset (like the Kaggle Language Detection dataset).\n",
    "\n",
    "**Objective:**\n",
    "- Prepare text data containing multiple languages.\n",
    "- Store it in a DataFrame for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39baf253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, how are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonjour, comment allez-vous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Namaste, aap kaise ho?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hola, buenos días.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciao, come stai?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hallo, wie geht es dir?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Olá, como vai você?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Привет, как дела?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>こんにちは、お元気ですか？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>안녕하세요, 어떻게 지내세요?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Text\n",
       "0           Hello, how are you?\n",
       "1  Bonjour, comment allez-vous?\n",
       "2        Namaste, aap kaise ho?\n",
       "3            Hola, buenos días.\n",
       "4              Ciao, come stai?\n",
       "5       Hallo, wie geht es dir?\n",
       "6           Olá, como vai você?\n",
       "7             Привет, как дела?\n",
       "8                 こんにちは、お元気ですか？\n",
       "9              안녕하세요, 어떻게 지내세요?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a small multilingual dataset\n",
    "data = {\n",
    "    \"Text\": [\n",
    "        \"Hello, how are you?\",                  # English\n",
    "        \"Bonjour, comment allez-vous?\",         # French\n",
    "        \"Namaste, aap kaise ho?\",               # Hindi\n",
    "        \"Hola, buenos días.\",                   # Spanish\n",
    "        \"Ciao, come stai?\",                     # Italian\n",
    "        \"Hallo, wie geht es dir?\",              # German\n",
    "        \"Olá, como vai você?\",                  # Portuguese\n",
    "        \"Привет, как дела?\",                    # Russian\n",
    "        \"こんにちは、お元気ですか？\",          # Japanese\n",
    "        \"안녕하세요, 어떻게 지내세요?\"             # Korean\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a8604",
   "metadata": {},
   "source": [
    "### Phase 2 – Language Detection using `langdetect`\n",
    "\n",
    "Now that our dataset is ready, we will use the `langdetect` library to identify the language of each sentence.  \n",
    "The `detect()` function analyzes the text and returns a two-letter language code such as:\n",
    "\n",
    "- `en` → English  \n",
    "- `fr` → French  \n",
    "- `es` → Spanish  \n",
    "- `hi` → Hindi  \n",
    "- `de` → German  \n",
    "- and so on.\n",
    "\n",
    "We will:\n",
    "1. Apply the detection function to each sentence in the DataFrame.\n",
    "2. Store the results in a new column called **Predicted_Language**.\n",
    "3. Display the DataFrame to verify the detected languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d52182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, how are you?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonjour, comment allez-vous?</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Namaste, aap kaise ho?</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hola, buenos días.</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciao, come stai?</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hallo, wie geht es dir?</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Olá, como vai você?</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Привет, как дела?</td>\n",
       "      <td>mk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>こんにちは、お元気ですか？</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>안녕하세요, 어떻게 지내세요?</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Text Predicted_Language\n",
       "0           Hello, how are you?                 en\n",
       "1  Bonjour, comment allez-vous?                 fr\n",
       "2        Namaste, aap kaise ho?                 et\n",
       "3            Hola, buenos días.                 es\n",
       "4              Ciao, come stai?                 it\n",
       "5       Hallo, wie geht es dir?                 de\n",
       "6           Olá, como vai você?                 pt\n",
       "7             Привет, как дела?                 mk\n",
       "8                 こんにちは、お元気ですか？                 ja\n",
       "9              안녕하세요, 어떻게 지내세요?                 ko"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # for consistent results\n",
    "\n",
    "# Function to detect language safely\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"error\"\n",
    "\n",
    "# Apply the function to each sentence\n",
    "df[\"Predicted_Language\"] = df[\"Text\"].apply(detect_language)\n",
    "\n",
    "# Display results\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1406e349",
   "metadata": {},
   "source": [
    "### Phase 3 – Converting Language Codes to Full Names\n",
    "\n",
    "While the `langdetect` library returns short two-letter language codes (ISO-639 format),  \n",
    "for presentation and analysis, it’s better to display the **full language names** such as  \n",
    "\"English\", \"French\", \"Hindi\", etc.\n",
    "\n",
    "To achieve this:\n",
    "1. We create a mapping dictionary of language codes to names.  \n",
    "2. We replace each code with its corresponding name using this dictionary.  \n",
    "3. Finally, we display the updated DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97de0673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Detected_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, how are you?</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonjour, comment allez-vous?</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Namaste, aap kaise ho?</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hola, buenos días.</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciao, come stai?</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hallo, wie geht es dir?</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Olá, como vai você?</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Привет, как дела?</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>こんにちは、お元気ですか？</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>안녕하세요, 어떻게 지내세요?</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Text Detected_Language\n",
       "0           Hello, how are you?           English\n",
       "1  Bonjour, comment allez-vous?            French\n",
       "2        Namaste, aap kaise ho?           Unknown\n",
       "3            Hola, buenos días.           Spanish\n",
       "4              Ciao, come stai?           Italian\n",
       "5       Hallo, wie geht es dir?            German\n",
       "6           Olá, como vai você?        Portuguese\n",
       "7             Привет, как дела?           Unknown\n",
       "8                 こんにちは、お元気ですか？          Japanese\n",
       "9              안녕하세요, 어떻게 지내세요?            Korean"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping of language codes to language names\n",
    "lang_map = {\n",
    "    'en': 'English', 'fr': 'French', 'es': 'Spanish', 'hi': 'Hindi',\n",
    "    'de': 'German', 'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian',\n",
    "    'ja': 'Japanese', 'ko': 'Korean', 'ar': 'Arabic', 'zh-cn': 'Chinese'\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df[\"Detected_Language\"] = df[\"Predicted_Language\"].map(lang_map).fillna(\"Unknown\")\n",
    "\n",
    "# Display final DataFrame\n",
    "df[[\"Text\", \"Detected_Language\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd03d5",
   "metadata": {},
   "source": [
    "### Phase 4 – Building an Interactive Language Detection Tool\n",
    "\n",
    "Now that our model can automatically detect languages from text,  \n",
    "we will make it interactive by allowing the user to enter sentences manually.  \n",
    "\n",
    "The system will:\n",
    "1. Accept user input.  \n",
    "2. Detect the language using `langdetect`.  \n",
    "3. Display both the language code and its full name.  \n",
    "4. Continue detecting until the user types **exit**.\n",
    "\n",
    "This interactive version demonstrates the practical application of the NLP tool in real-world text processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ed2e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Language Code: et\n",
      "Detected Language Name: Unknown Language\n",
      "--------------------------------------------------\n",
      "Detected Language Code: en\n",
      "Detected Language Name: English\n",
      "--------------------------------------------------\n",
      "Detected Language Code: error\n",
      "Detected Language Name: Could not detect\n",
      "--------------------------------------------------\n",
      "Exiting Language Detector. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Mapping language codes to readable names\n",
    "lang_map = {\n",
    "    'en': 'English', 'fr': 'French', 'es': 'Spanish', 'hi': 'Hindi', \n",
    "    'de': 'German', 'it': 'Italian', 'pt': 'Portuguese', 'nl': 'Dutch',\n",
    "    'ru': 'Russian', 'ja': 'Japanese', 'ko': 'Korean', 'ar': 'Arabic', \n",
    "    'zh-cn': 'Chinese'\n",
    "}\n",
    "\n",
    "def detect_language_live(text):\n",
    "    try:\n",
    "        code = detect(text)\n",
    "        name = lang_map.get(code, \"Unknown Language\")\n",
    "        return code, name\n",
    "    except:\n",
    "        return \"error\", \"Could not detect\"\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    text = input(\"Enter a sentence (or type 'exit' to stop): \")\n",
    "    if text.lower() == 'exit':\n",
    "        print(\"Exiting Language Detector. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    code, name = detect_language_live(text)\n",
    "    print(f\"Detected Language Code: {code}\")\n",
    "    print(f\"Detected Language Name: {name}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a30b30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3ef8dcc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
